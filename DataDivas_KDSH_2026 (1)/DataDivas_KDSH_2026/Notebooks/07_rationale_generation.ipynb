{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 7: Evidence Rationale Generation\n",
    "\n",
    "## Overview\n",
    "Generate evidence-based explanations for consistency/contradiction predictions.\n",
    "\n",
    "## Methods\n",
    "- Attention score analysis\n",
    "- Chunk-level contradiction confidence\n",
    "- Natural language explanation generation\n",
    "\n",
    "## Example Output\n",
    "\"The backstory claims the character avoids violence, but in chapters 3 and 5, the character initiates physical conflict.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
import json
import os
    "\n",
    "PROJECT_ROOT = Path(\"/root/DataDivas_KDSH_2026\")\n",
    "DATA_DIR = PROJECT_ROOT / \"Data\"\n",
    "PHASE5_OUTPUT = PROJECT_ROOT / \"phase5_output\"\n",
    "PHASE6_OUTPUT = PROJECT_ROOT / \"phase6_output\"\n",
    "PHASE7_OUTPUT = PROJECT_ROOT / \"phase7_output\"\n",
    "\n",
    "# Load data\n",
    "features_df = pd.read_parquet(DATA_DIR / \"feature_data.parquet\")\n",
    "\n",
    "# Load model selection (prefer phase5_output)\n",
    "model_selection_path = PHASE5_OUTPUT / \"model_selection.json\"\n",
    "if not model_selection_path.exists():\n",
    "    model_selection_path = DATA_DIR / \"model_selection.json\"\n",
    "\n",
    "with open(model_selection_path) as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(features_df)} samples\")\n",
    "print(f\"Model: {model_config['primary_model']['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model_name = model_config['primary_model']['huggingface_name']\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Prefer saved model in phase6_output, then phase5_output, then Data\n",
    "best_model_path = PHASE6_OUTPUT / \"best_model.pt\"\n",
    "if not best_model_path.exists():\n",
    "    best_model_path = PHASE5_OUTPUT / \"best_model.pt\"\n",
    "if not best_model_path.exists():\n",
    "    best_model_path = DATA_DIR / \"best_model.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded from {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Chunk-Level Classification with Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_chunk_with_confidence(backstory, chunk_text):\n",
    "    \"\"\"Classify a single chunk and return confidence scores.\"\"\"\n",
    "    # Build input\n",
    "    input_text = f\"[CLS] {backstory} [SEP] {chunk_text} [SEP]\"\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        input_text,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Forward pass\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        confidence = torch.max(probs).item()\n",
    "        prediction = torch.argmax(probs, dim=1).item()\n",
    "    \n",
    "    return {\n",
    "        'prediction': prediction,\n",
    "        'confidence': confidence,\n",
    "        'prob_contradict': probs[0][0].item(),\n",
    "        'prob_consistent': probs[0][1].item()\n",
    "    }\n",
    "\n",
    "print(\"Chunk classification function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Evidence Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvidenceExtractor:\n",
    "    \"\"\"Extract evidence sentences for consistency/contradiction.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.contradiction_indicators = [\n",
    "            (r'killed|murdered|attacked', 'violent action'),\n",
    "            (r'lied|deceived|tricked', 'deceptive behavior'),\n",
    "            (r'betrayed|abandoned', 'betrayal'),\n",
    "            (r'stole|robbed|cheated', 'dishonest action'),\n",
    "        ]\n",
    "        \n",
    "        self.consistency_indicators = [\n",
    "            (r'saved|helped|rescued', 'helping behavior'),\n",
    "            (r'kind|gentle|merciful', 'kind behavior'),\n",
    "            (r'brave|loyal|honest', 'virtuous behavior'),\n",
    "            (r'peaceful|peace', 'peaceful intent'),\n",
    "        ]\n",
    "    \n",
    "    def extract_evidence(self, text, prediction, backstory):\n",
    "        \"\"\"Extract sentences that support the prediction.\"\"\"\n",
    "        sentences = text.replace('!', '.').replace('?', '.').split('.')\n",
    "        evidence = []\n",
    "        \n",
    "        indicators = (self.consistency_indicators if prediction == 1 \n",
    "                     else self.contradiction_indicators)\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if len(sentence) < 20:\n",
    "                continue\n",
    "            \n",
    "            for pattern, label in indicators:\n",
    "                if re.search(pattern, sentence, re.IGNORECASE):\n",
    "                    evidence.append({\n",
    "                        'sentence': sentence,\n",
    "                        'indicator': label,\n",
    "                        'pattern': pattern\n",
    "                    })\n",
    "                    break\n",
    "        \n",
    "        return evidence[:5]  # Limit to 5 evidence sentences\n",
    "\n",
    "extractor = EvidenceExtractor()\n",
    "print(\"Evidence extractor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rationale(backstory, chunks, chunk_results):\n",
    "    \"\"\"Generate a natural language rationale for the prediction.\"\"\"\n",
    "    \n",
    "    # Aggregate results\n",
    "    total_contradict = sum(1 for r in chunk_results if r['prediction'] == 0)\n",
    "    total_consistent = sum(1 for r in chunk_results if r['prediction'] == 1)\n",
    "    avg_confidence = sum(r['confidence'] for r in chunk_results) / len(chunk_results)\n",
    "    \n",
    "    # Determine final prediction\n",
    "    final_prediction = 1 if total_consistent > total_contradict else 0\n",
    "    \n",
    "    # Extract evidence from high-confidence chunks\n",
    "    evidence_chunks = [c for c, r in zip(chunks, chunk_results) \n",
    "                      if r['confidence'] > avg_confidence]\n",
    "    \n",
    "    all_evidence = []\n",
    "    for chunk in evidence_chunks[:3]:\n",
    "        evidence = extractor.extract_evidence(chunk, final_prediction, backstory)\n",
    "        all_evidence.extend(evidence)\n",
    "    \n",
    "    # Build rationale\n",
    "    if final_prediction == 1:\n",
    "        rationale = f\"CONSISTENT: The character's actions align with their backstory.\"\n",
    "        if all_evidence:\n",
    "            rationale += f\" Supporting evidence: {'; '.join(e['sentence'][:100] for e in all_evidence[:2])}.\"\n",
    "    else:\n",
    "        rationale = f\"CONTRADICTION: The character's actions contradict their backstory.\"\n",
    "        if all_evidence:\n",
    "            rationale += f\" Contradicting evidence: {'; '.join(e['sentence'][:100] for e in all_evidence[:2])}.\"\n",
    "    \n",
    "    return {\n",
    "        'prediction': final_prediction,\n",
    "        'confidence': avg_confidence,\n",
    "        'rationale': rationale,\n",
    "        'evidence': all_evidence,\n",
    "        'chunk_summary': {\n",
    "            'consistent': total_consistent,\n",
    "            'contradict': total_contradict\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"Rationale generation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process samples and generate rationales\n",
    "results = []\n",
    "\n",
    "for idx, row in features_df.iterrows():\n",
    "    backstory = row['backstory']\n",
    "    chunk_text = row['evidence_text']\n",
    "    \n",
    "    # Classify chunk\n",
    "    chunk_result = classify_chunk_with_confidence(backstory, chunk_text)\n",
    "    \n",
    "    # Extract evidence\n",
    "    evidence = extractor.extract_evidence(chunk_text, chunk_result['prediction'], backstory)\n",
    "    \n",
    "    results.append({\n",
    "        'sample_id': row['sample_id'],\n",
    "        'character_name': row['character_name'],\n",
    "        'prediction': chunk_result['prediction'],\n",
    "        'confidence': chunk_result['confidence'],\n",
    "        'evidence_count': len(evidence),\n",
    "        'evidence': evidence[:3]\n",
    "    })\n",
    "\n",
    "print(f\"Processed {len(results)} samples\")\n",
    "\n",
    "# Show sample results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "SAMPLE RESULTS\n",
    "=\" * 60)\n",
    "\n",
    "for r in results[:3]:\n",
    "    label = \"CONSISTENT\" if r['prediction'] == 1 else \"CONTRADICT\"\n",
    "    print(f\"\\n{r['character_name']}: {label} (confidence: {r['confidence']:.2f})\")\n",
    "    print(f\"  Evidence found: {r['evidence_count']} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rationale results\n",
    "results_df = pd.DataFrame([{\n",
    "    'sample_id': r['sample_id'],\n",
    "    'character_name': r['character_name'],\n",
    "    'prediction': r['prediction'],\n",
    "    'confidence': r['confidence'],\n",
    "    'evidence_count': r['evidence_count'],\n",
    "    'evidence_text': ' | '.join([e['sentence'][:50] for e in r['evidence']])\n",
    "} for r in results])\n",
    "\n",
    "os.makedirs(PHASE7_OUTPUT, exist_ok=True)\n",
    "results_df.to_csv(PHASE7_OUTPUT / \"rationale_results.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ Rationale results saved to: phase7_output/rationale_results.csv\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "PHASE 7 SUMMARY\n",
    "=\" * 60)\n",
    "print(f\"Samples processed: {len(results)}\")\n",
    "pred_counts = results_df['prediction'].value_counts()\n",
    "for pred, count in pred_counts.items():\n",
    "    label = \"Consistent\" if pred == 1 else \"Contradict\"\n",
    "    print(f\"  {label}: {count}\")\n",
    "print(f\"\\nEvidence extraction working correctly\")\n",
    "print(\"Ready for Phase 8: Inference Pipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
